{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trump.txt', 'r') as f:\n",
    "    speech = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for word in speech.lower().split():\n",
    "    if word not in stopwords:\n",
    "        if word not in dic:\n",
    "            dic[word] = 1\n",
    "        else:\n",
    "            dic[word] = dic[word] + 1\n",
    "#dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('american', 11)\n",
      "('america', 10)\n",
      "('again.', 8)\n",
      "('president', 6)\n",
      "('people', 6)\n",
      "('great', 6)\n",
      "('country', 6)\n",
      "('new', 6)\n",
      "('right', 5)\n",
      "('make', 5)\n",
      "('america,', 4)\n",
      "('world', 4)\n",
      "('today', 4)\n",
      "('nation', 4)\n",
      "('bring', 4)\n",
      "('people.', 3)\n",
      "('together,', 3)\n",
      "('you,', 3)\n",
      "('nation’s', 3)\n",
      "('factories', 3)\n",
      "('protected', 3)\n",
      "('america.', 3)\n",
      "('millions', 3)\n",
      "('foreign', 3)\n",
      "('countries', 3)\n",
      "('let', 3)\n",
      "('heart', 3)\n",
      "('inaugural', 2)\n",
      "('address', 2)\n",
      "('prepared', 2)\n",
      "('delivery', 2)\n",
      "('january', 2)\n",
      "('washington,', 2)\n",
      "('d.c.', 2)\n",
      "('americans,', 2)\n",
      "('thank', 2)\n",
      "('you.', 2)\n",
      "('citizens', 2)\n",
      "('national', 2)\n",
      "('face', 2)\n",
      "('done.', 2)\n",
      "('obama', 2)\n",
      "('transferring', 2)\n",
      "('power', 2)\n",
      "('party', 2)\n",
      "('small', 2)\n",
      "('government', 2)\n",
      "('share', 2)\n",
      "('wealth.', 2)\n",
      "('politicians', 2)\n",
      "('jobs', 2)\n",
      "('country.', 2)\n",
      "('capital,', 2)\n",
      "('land.', 2)\n",
      "('moment', 2)\n",
      "('belongs', 2)\n",
      "('united', 2)\n",
      "('states', 2)\n",
      "('day', 2)\n",
      "('forgotten', 2)\n",
      "('men', 2)\n",
      "('women', 2)\n",
      "('now.', 2)\n",
      "('movement', 2)\n",
      "('before.', 2)\n",
      "('safe', 2)\n",
      "('good', 2)\n",
      "('like', 2)\n",
      "('stops', 2)\n",
      "('glorious', 2)\n",
      "('destiny.', 2)\n",
      "('oath', 2)\n",
      "('allegiance', 2)\n",
      "('we’ve', 2)\n",
      "('borders', 2)\n",
      "('left', 2)\n",
      "('workers', 2)\n",
      "('first.', 2)\n",
      "('jobs.', 2)\n",
      "('fight', 2)\n",
      "('breath', 2)\n",
      "('winning', 2)\n",
      "('seek', 2)\n",
      "('nations', 2)\n",
      "('life', 2)\n",
      "('old', 2)\n",
      "('loyalty', 2)\n",
      "('and,', 2)\n",
      "('talk', 2)\n",
      "('time', 2)\n",
      "('dreams,', 2)\n",
      "('god', 2)\n",
      "('bless', 2)\n",
      "('remarks', 1)\n",
      "('donald', 1)\n",
      "('j.', 1)\n",
      "('trump', 1)\n",
      "('friday,', 1)\n",
      "('20,', 1)\n",
      "('2017', 1)\n",
      "('chief', 1)\n",
      "('justice', 1)\n",
      "('roberts,', 1)\n",
      "('carter,', 1)\n",
      "('clinton,', 1)\n",
      "('bush,', 1)\n",
      "('obama,', 1)\n",
      "('fellow', 1)\n",
      "('world:', 1)\n",
      "('we,', 1)\n",
      "('joined', 1)\n",
      "('effort', 1)\n",
      "('rebuild', 1)\n",
      "('restore', 1)\n",
      "('promise', 1)\n",
      "('determine', 1)\n",
      "('course', 1)\n",
      "('years', 1)\n",
      "('come.', 1)\n",
      "('challenges.', 1)\n",
      "('confront', 1)\n",
      "('hardships.', 1)\n",
      "('job', 1)\n",
      "('years,', 1)\n",
      "('gather', 1)\n",
      "('steps', 1)\n",
      "('carry', 1)\n",
      "('orderly', 1)\n",
      "('peaceful', 1)\n",
      "('transfer', 1)\n",
      "('power,', 1)\n",
      "('grateful', 1)\n",
      "('lady', 1)\n",
      "('michelle', 1)\n",
      "('gracious', 1)\n",
      "('aid', 1)\n",
      "('transition.', 1)\n",
      "('magnificent.', 1)\n",
      "('today’s', 1)\n",
      "('ceremony,', 1)\n",
      "('however,', 1)\n",
      "('special', 1)\n",
      "('meaning.', 1)\n",
      "('merely', 1)\n",
      "('administration', 1)\n",
      "('another,', 1)\n",
      "('giving', 1)\n",
      "('long,', 1)\n",
      "('group', 1)\n",
      "('capital', 1)\n",
      "('reaped', 1)\n",
      "('rewards', 1)\n",
      "('borne', 1)\n",
      "('cost.', 1)\n",
      "('washington', 1)\n",
      "('flourished', 1)\n",
      "('did', 1)\n",
      "('prospered', 1)\n",
      "('left,', 1)\n",
      "('closed.', 1)\n",
      "('establishment', 1)\n",
      "('itself,', 1)\n",
      "('victories', 1)\n",
      "('victories;', 1)\n",
      "('triumphs', 1)\n",
      "('triumphs;', 1)\n",
      "('celebrated', 1)\n",
      "('little', 1)\n",
      "('celebrate', 1)\n",
      "('struggling', 1)\n",
      "('families', 1)\n",
      "('changes', 1)\n",
      "('starting', 1)\n",
      "('here,', 1)\n",
      "('now,', 1)\n",
      "('moment:', 1)\n",
      "('gathered', 1)\n",
      "('watching', 1)\n",
      "('day.', 1)\n",
      "('celebration.', 1)\n",
      "('this,', 1)\n",
      "('truly', 1)\n",
      "('matters', 1)\n",
      "('controls', 1)\n",
      "('government,', 1)\n",
      "('controlled', 1)\n",
      "('20th', 1)\n",
      "('2017,', 1)\n",
      "('remembered', 1)\n",
      "('rulers', 1)\n",
      "('longer.', 1)\n",
      "('listening', 1)\n",
      "('came', 1)\n",
      "('tens', 1)\n",
      "('historic', 1)\n",
      "('likes', 1)\n",
      "('seen', 1)\n",
      "('center', 1)\n",
      "('crucial', 1)\n",
      "('conviction:', 1)\n",
      "('exists', 1)\n",
      "('serve', 1)\n",
      "('citizens.', 1)\n",
      "('americans', 1)\n",
      "('want', 1)\n",
      "('schools', 1)\n",
      "('children,', 1)\n",
      "('neighborhoods', 1)\n",
      "('families,', 1)\n",
      "('themselves.', 1)\n",
      "('just', 1)\n",
      "('reasonable', 1)\n",
      "('demands', 1)\n",
      "('righteous', 1)\n",
      "('public.', 1)\n",
      "('citizens,', 1)\n",
      "('different', 1)\n",
      "('reality', 1)\n",
      "('exists:', 1)\n",
      "('mothers', 1)\n",
      "('children', 1)\n",
      "('trapped', 1)\n",
      "('poverty', 1)\n",
      "('inner', 1)\n",
      "('cities;', 1)\n",
      "('rusted-out', 1)\n",
      "('scattered', 1)\n",
      "('tombstones', 1)\n",
      "('landscape', 1)\n",
      "('nation;', 1)\n",
      "('education', 1)\n",
      "('system,', 1)\n",
      "('flush', 1)\n",
      "('cash,', 1)\n",
      "('leaves', 1)\n",
      "('young', 1)\n",
      "('beautiful', 1)\n",
      "('students', 1)\n",
      "('deprived', 1)\n",
      "('knowledge;', 1)\n",
      "('crime', 1)\n",
      "('gangs', 1)\n",
      "('drugs', 1)\n",
      "('stolen', 1)\n",
      "('lives', 1)\n",
      "('robbed', 1)\n",
      "('unrealized', 1)\n",
      "('potential.', 1)\n",
      "('carnage', 1)\n",
      "('pain', 1)\n",
      "('pain.', 1)\n",
      "('dreams', 1)\n",
      "('dreams;', 1)\n",
      "('success', 1)\n",
      "('success.', 1)\n",
      "('heart,', 1)\n",
      "('home,', 1)\n",
      "('office', 1)\n",
      "('americans.', 1)\n",
      "('decades,', 1)\n",
      "('enriched', 1)\n",
      "('industry', 1)\n",
      "('expense', 1)\n",
      "('industry;', 1)\n",
      "('subsidized', 1)\n",
      "('armies', 1)\n",
      "('allowing', 1)\n",
      "('sad', 1)\n",
      "('depletion', 1)\n",
      "('military;', 1)\n",
      "(\"we've\", 1)\n",
      "('defended', 1)\n",
      "('refusing', 1)\n",
      "('defend', 1)\n",
      "('own;', 1)\n",
      "('spent', 1)\n",
      "('trillions', 1)\n",
      "('dollars', 1)\n",
      "('overseas', 1)\n",
      "(\"america's\", 1)\n",
      "('infrastructure', 1)\n",
      "('fallen', 1)\n",
      "('disrepair', 1)\n",
      "('decay.', 1)\n",
      "('rich', 1)\n",
      "('wealth,', 1)\n",
      "('strength,', 1)\n",
      "('confidence', 1)\n",
      "('disappeared', 1)\n",
      "('horizon.', 1)\n",
      "('one,', 1)\n",
      "('shuttered', 1)\n",
      "('shores,', 1)\n",
      "('thought', 1)\n",
      "('behind.', 1)\n",
      "('wealth', 1)\n",
      "('middle', 1)\n",
      "('class', 1)\n",
      "('ripped', 1)\n",
      "('homes', 1)\n",
      "('redistributed', 1)\n",
      "('entire', 1)\n",
      "('world.', 1)\n",
      "('past.', 1)\n",
      "('looking', 1)\n",
      "('future.', 1)\n",
      "('assembled', 1)\n",
      "('issuing', 1)\n",
      "('decree', 1)\n",
      "('heard', 1)\n",
      "('city,', 1)\n",
      "('hall', 1)\n",
      "('power.', 1)\n",
      "('forward,', 1)\n",
      "('vision', 1)\n",
      "('govern', 1)\n",
      "('on,', 1)\n",
      "('it’s', 1)\n",
      "('going', 1)\n",
      "('decision', 1)\n",
      "('trade,', 1)\n",
      "('taxes,', 1)\n",
      "('immigration,', 1)\n",
      "('affairs,', 1)\n",
      "('benefit', 1)\n",
      "('families.', 1)\n",
      "('protect', 1)\n",
      "('ravages', 1)\n",
      "('making', 1)\n",
      "('products,', 1)\n",
      "('stealing', 1)\n",
      "('companies,', 1)\n",
      "('destroying', 1)\n",
      "('protection', 1)\n",
      "('lead', 1)\n",
      "('prosperity', 1)\n",
      "('strength.', 1)\n",
      "('body', 1)\n",
      "('never,', 1)\n",
      "('down.', 1)\n",
      "('start', 1)\n",
      "('again,', 1)\n",
      "('borders.', 1)\n",
      "('dreams.', 1)\n",
      "('build', 1)\n",
      "('roads,', 1)\n",
      "('highways,', 1)\n",
      "('bridges,', 1)\n",
      "('airports,', 1)\n",
      "('tunnels,', 1)\n",
      "('railways', 1)\n",
      "('wonderful', 1)\n",
      "('nation.', 1)\n",
      "('welfare', 1)\n",
      "('work', 1)\n",
      "('rebuilding', 1)\n",
      "('hands', 1)\n",
      "('labor.', 1)\n",
      "('follow', 1)\n",
      "('simple', 1)\n",
      "('rules:', 1)\n",
      "('buy', 1)\n",
      "('hire', 1)\n",
      "('american.', 1)\n",
      "('friendship', 1)\n",
      "('goodwill', 1)\n",
      "('understanding', 1)\n",
      "('interests', 1)\n",
      "('impose', 1)\n",
      "('way', 1)\n",
      "('anyone,', 1)\n",
      "('shine', 1)\n",
      "('example', 1)\n",
      "('follow.', 1)\n",
      "('reinforce', 1)\n",
      "('alliances', 1)\n",
      "('form', 1)\n",
      "('ones', 1)\n",
      "('unite', 1)\n",
      "('civilized', 1)\n",
      "('radical', 1)\n",
      "('islamic', 1)\n",
      "('terrorism,', 1)\n",
      "('eradicate', 1)\n",
      "('completely', 1)\n",
      "('earth.', 1)\n",
      "('bedrock', 1)\n",
      "('politics', 1)\n",
      "('total', 1)\n",
      "('country,', 1)\n",
      "('rediscover', 1)\n",
      "('other.', 1)\n",
      "('open', 1)\n",
      "('patriotism,', 1)\n",
      "('room', 1)\n",
      "('prejudice.', 1)\n",
      "('bible', 1)\n",
      "('tells', 1)\n",
      "('us,', 1)\n",
      "('“how', 1)\n",
      "('pleasant', 1)\n",
      "('god’s', 1)\n",
      "('live', 1)\n",
      "('unity.”', 1)\n",
      "('speak', 1)\n",
      "('minds', 1)\n",
      "('openly,', 1)\n",
      "('debate', 1)\n",
      "('disagreements', 1)\n",
      "('honestly,', 1)\n",
      "('pursue', 1)\n",
      "('solidarity.', 1)\n",
      "('united,', 1)\n",
      "('totally', 1)\n",
      "('unstoppable.', 1)\n",
      "('fear', 1)\n",
      "('protected,', 1)\n",
      "('protected.', 1)\n",
      "('military', 1)\n",
      "('law', 1)\n",
      "('enforcement', 1)\n",
      "('importantly,', 1)\n",
      "('god.', 1)\n",
      "('finally,', 1)\n",
      "('think', 1)\n",
      "('big', 1)\n",
      "('dream', 1)\n",
      "('bigger.', 1)\n",
      "('understand', 1)\n",
      "('living', 1)\n",
      "('long', 1)\n",
      "('striving.', 1)\n",
      "('longer', 1)\n",
      "('accept', 1)\n",
      "('action', 1)\n",
      "('constantly', 1)\n",
      "('complaining', 1)\n",
      "('doing', 1)\n",
      "('it.', 1)\n",
      "('over.', 1)\n",
      "('arrives', 1)\n",
      "('hour', 1)\n",
      "('action.', 1)\n",
      "('tell', 1)\n",
      "('challenge', 1)\n",
      "('match', 1)\n",
      "('spirit', 1)\n",
      "('fail.', 1)\n",
      "('thrive', 1)\n",
      "('prosper', 1)\n",
      "('stand', 1)\n",
      "('birth', 1)\n",
      "('millennium,', 1)\n",
      "('ready', 1)\n",
      "('unlock', 1)\n",
      "('mysteries', 1)\n",
      "('space,', 1)\n",
      "('free', 1)\n",
      "('earth', 1)\n",
      "('miseries', 1)\n",
      "('disease,', 1)\n",
      "('harness', 1)\n",
      "('energies,', 1)\n",
      "('industries', 1)\n",
      "('technologies', 1)\n",
      "('tomorrow.', 1)\n",
      "('pride', 1)\n",
      "('stir', 1)\n",
      "('souls,', 1)\n",
      "('lift', 1)\n",
      "('sights,', 1)\n",
      "('heal', 1)\n",
      "('divisions.', 1)\n",
      "('remember', 1)\n",
      "('wisdom', 1)\n",
      "('soldiers', 1)\n",
      "('forget:', 1)\n",
      "('black', 1)\n",
      "('brown', 1)\n",
      "('white,', 1)\n",
      "('bleed', 1)\n",
      "('red', 1)\n",
      "('blood', 1)\n",
      "('patriots,', 1)\n",
      "('enjoy', 1)\n",
      "('freedoms,', 1)\n",
      "('salute', 1)\n",
      "('flag.', 1)\n",
      "('child', 1)\n",
      "('born', 1)\n",
      "('urban', 1)\n",
      "('sprawl', 1)\n",
      "('detroit', 1)\n",
      "('windswept', 1)\n",
      "('plains', 1)\n",
      "('nebraska,', 1)\n",
      "('look', 1)\n",
      "('night', 1)\n",
      "('sky,', 1)\n",
      "('infused', 1)\n",
      "('almighty', 1)\n",
      "('creator.', 1)\n",
      "('city', 1)\n",
      "('near', 1)\n",
      "('far,', 1)\n",
      "('large,', 1)\n",
      "('mountain', 1)\n",
      "('mountain,', 1)\n",
      "('ocean', 1)\n",
      "('ocean,', 1)\n",
      "('hear', 1)\n",
      "('words:', 1)\n",
      "('ignored', 1)\n",
      "('voice,', 1)\n",
      "('hopes,', 1)\n",
      "('define', 1)\n",
      "('courage', 1)\n",
      "('goodness', 1)\n",
      "('love', 1)\n",
      "('forever', 1)\n",
      "('guide', 1)\n",
      "('way.', 1)\n",
      "('strong', 1)\n",
      "('wealthy', 1)\n",
      "('proud', 1)\n",
      "('yes,', 1)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "for ele in sorted(dic.items(), key = operator.itemgetter(1), reverse=True):\n",
    "    if len(ele[0]) > 1:\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('american', 11),\n",
       " ('america', 10),\n",
       " ('again.', 8),\n",
       " ('president', 6),\n",
       " ('people', 6),\n",
       " ('great', 6),\n",
       " ('country', 6),\n",
       " ('new', 6),\n",
       " ('right', 5),\n",
       " ('make', 5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter([ele.lower() for ele in speech.split() if ele.lower() not in stopwords and len(ele) > 1])\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('c://Users//TNY//obama.txt','r') as f:\n",
    "    speech = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "words = speech.lower().split()\n",
    "for w in words:\n",
    "    if w not in stopwords:\n",
    "        if w not in dic:\n",
    "            dic[w] = 1\n",
    "        else:\n",
    "            dic[w] = dic[w] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "swd = sorted(dic.items(), key = operator.itemgetter(1), reverse = True)\n",
    "#swd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 16\n",
      "nation 10\n",
      "us, 9\n",
      "new 9\n",
      "common 6\n",
      "let 6\n",
      "know 5\n",
      "time 5\n",
      "people 5\n",
      "america 4\n"
     ]
    }
   ],
   "source": [
    "for key,val in swd[0:10]:\n",
    "    #key, val = rec\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('c://Users//TNY//obama.txt','r') as f:\n",
    "    speech = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--', 16),\n",
       " ('nation', 10),\n",
       " ('us,', 9),\n",
       " ('new', 9),\n",
       " ('common', 6),\n",
       " ('let', 6),\n",
       " ('know', 5),\n",
       " ('time', 5),\n",
       " ('people', 5),\n",
       " ('america', 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = []\n",
    "for w in speech.lower().split():\n",
    "    if w not in stopwords:\n",
    "        words.append(w)\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2,3,6,9,1,8,5]\n",
    "ary = []\n",
    "for ele in a:\n",
    "    if ele < 5:\n",
    "        ary.append(ele)\n",
    "ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ele for ele  in a if ele < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('c://Users//TNY//obama.txt','r') as f:\n",
    "    speech = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--', 16),\n",
       " ('nation', 10),\n",
       " ('us,', 9),\n",
       " ('new', 9),\n",
       " ('common', 6),\n",
       " ('let', 6),\n",
       " ('know', 5),\n",
       " ('time', 5),\n",
       " ('people', 5),\n",
       " ('america', 4)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = [w for w in speech.lower().split() if w not in stopwords]\n",
    "c = Counter(words)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\users\\tny\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\TNY\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.362 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蔡英文\n",
      "就職\n",
      "演說\n",
      "全文\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.add_word('蔡英文')\n",
    "jieba.add_word('就職')\n",
    "for w in jieba.cut('蔡英文就職演說全文'):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('C://Users/TNY//president.txt', 'r') as f:\n",
    "    speech = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我們 85\n",
      "台灣 39\n",
      "國家 28\n",
      "新政府 27\n",
      "經濟 26\n",
      "這個 24\n",
      "一個 24\n",
      "民主 22\n",
      "發展 20\n",
      "社會 19\n",
      "人民 18\n",
      "就是 18\n",
      "共同 15\n",
      "未來 15\n",
      "改革 15\n",
      "議題 14\n",
      "司法 13\n",
      "區域 11\n",
      "政府 10\n",
      "合作 10\n",
      "和平 9\n",
      "必須 9\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter([w for w in jieba.cut(speech)])\n",
    "for word, cnt in c.most_common(50):\n",
    "    if len(word) >= 2:\n",
    "        print(word, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-1.2.2.tar.gz\n",
      "Requirement already satisfied: six in c:\\users\\tny\\anaconda3\\lib\\site-packages (from gTTS)\n",
      "Requirement already satisfied: requests in c:\\users\\tny\\anaconda3\\lib\\site-packages (from gTTS)\n",
      "Collecting gtts_token (from gTTS)\n",
      "  Downloading gTTS-token-1.1.1.zip\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\tny\\anaconda3\\lib\\site-packages (from requests->gTTS)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\tny\\anaconda3\\lib\\site-packages (from requests->gTTS)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\tny\\anaconda3\\lib\\site-packages (from requests->gTTS)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tny\\anaconda3\\lib\\site-packages (from requests->gTTS)\n",
      "Building wheels for collected packages: gTTS, gtts-token\n",
      "  Running setup.py bdist_wheel for gTTS: started\n",
      "  Running setup.py bdist_wheel for gTTS: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\TNY\\AppData\\Local\\pip\\Cache\\wheels\\ef\\e7\\2e\\066d7be1514f7c7fd6c942f4d09ae5460f9a3125829782d03d\n",
      "  Running setup.py bdist_wheel for gtts-token: started\n",
      "  Running setup.py bdist_wheel for gtts-token: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\TNY\\AppData\\Local\\pip\\Cache\\wheels\\a9\\19\\5d\\2abe941153d0331bb7c2fbcd48ed8c36a67ca1d40bd572773e\n",
      "Successfully built gTTS gtts-token\n",
      "Installing collected packages: gtts-token, gTTS\n",
      "Successfully installed gTTS-1.2.2 gtts-token-1.1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-1.9.3-cp36-cp36m-win_amd64.whl (4.2MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-1.9.3\n"
     ]
    }
   ],
   "source": [
    "! pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讓電腦講話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "import tempfile\n",
    "\n",
    "mixer.init()\n",
    "\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts = gTTS(text=sentence, lang='zh')\n",
    "        tts.save(\"[].mp3\".format(fp.name))\n",
    "        mixer.music.load('[].mp3'.format(fp.name))\n",
    "        mixer.music.play()\n",
    "speak('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
